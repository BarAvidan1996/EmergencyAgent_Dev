import { NextResponse } from 'next/server'
import { createClient } from '@supabase/supabase-js'
import { OpenAI } from '@langchain/openai'
import { OpenAIEmbeddings } from '@langchain/openai'
import { PromptTemplate } from '@langchain/core/prompts'

const OPENAI_API_KEY = process.env.OPENAI_API_KEY!
const SUPABASE_URL = 'https://lfmxtaefgvjbuipcdcya.supabase.co'
const SUPABASE_SERVICE_ROLE_KEY = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImxmbXh0YWVmZ3ZqYnVpcGNkY3lhIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTc0NDI5ODk0OSwiZXhwIjoyMDU5ODc0OTQ5fQ.i8Z7Z2ee7_kYCWBtBELuKL1M3wg6Pj_1aRF_BpIyQ8Y'

const supabase = createClient(SUPABASE_URL, SUPABASE_SERVICE_ROLE_KEY)
const llm = new OpenAI({ 
  openAIApiKey: OPENAI_API_KEY,
  modelName: 'gpt-4',
  temperature: 0
})
const fallbackLLM = new OpenAI({ 
  openAIApiKey: OPENAI_API_KEY,
  modelName: 'gpt-4',
  temperature: 0
})
const embeddings = new OpenAIEmbeddings({ openAIApiKey: OPENAI_API_KEY })

const PROMPT_TEMPLATE = `
××ª×” ×¢×•×–×¨ ×—×›× ×œ×¤×™×§×•×“ ×”×¢×•×¨×£ ×‘×™×©×¨××œ.
×”×ž×˜×¨×” ×©×œ×š ×”×™× ×œ×¡×¤×§ ×ª×©×•×‘×•×ª ×ž×“×•×™×§×•×ª, ××ž×™× ×•×ª ×•×¢×“×›× ×™×•×ª ×œ×©××œ×•×ª ×”×§×©×•×¨×•×ª ×œ×ž×¦×‘×™ ×—×™×¨×•× ×‘×™×©×¨××œ.

ðŸ”¹ ×”×©×ª×ž×© ××š ×•×¨×§ ×‘×ž×™×“×¢ ×”×ž×•×‘× ×œ×ž×˜×”.  
ðŸ”¹ ×× ××™×Ÿ ×‘×ž×™×“×¢ ×ª×©×•×‘×” ×‘×¨×•×¨×” â€” ×¦×™×™×Ÿ ×‘×ž×¤×•×¨×©: "×œ× × ×ž×¦××” ×ª×©×•×‘×” ×ž×‘×•×¡×¡×ª ×‘×ž×™×“×¢ ×”× ×ª×•×Ÿ."
ðŸ”¹ ×›×ª×•×‘ ×‘×¢×‘×¨×™×ª ×ª×§× ×™×ª, ×¨×”×•×˜×” ×•×¨×©×ž×™×ª, ×‘×¡×’× ×•×Ÿ ×”×ž×ª××™× ×œ×¤×¨×¡×•× ×©×œ ×¨×©×•×ª ×ž×ž×©×œ×ª×™×ª.
ðŸ”¹ ×¡×“×¨ ××ª ×”×ª×©×•×‘×” ×‘×¦×•×¨×” ×‘×¨×•×¨×”, ×¢× ×¡×¢×™×¤×™× ×ž×ž×•×¡×¤×¨×™× ×× ×¦×¨×™×š.
ðŸ”¹ ×‘×¡×™×•× ×”×ª×©×•×‘×”, ×”×•×¡×£ ×©×•×¨×ª ×ž×§×•×¨×•×ª ×¢× ×©×ž×•×ª ×”×§×‘×¦×™× ×©×”×ª×‘×¡×¡×ª ×¢×œ×™×”×.

ðŸ“„ ×ž×™×“×¢ ×¨×œ×•×•× ×˜×™:
{context}

â“ ×©××œ×”:
{question}

ðŸ“ ×ª×©×•×‘×”:
`;

const STEPBACK_PROMPT_TEMPLATE = `
×œ×¤× ×™ ×©×ª×¢× ×” ×™×©×™×¨×•×ª ×¢×œ ×”×©××œ×”, ×§×— ×¦×¢×“ ××—×•×¨×”:
1. × ×ª×— ××ª ×”×”×§×©×¨ ×”×›×œ×œ×™ ×©×œ ×”×ž×¦×‘.
2. ×§×‘×¢ ×ž×”×• ×”×ž×™×“×¢ ×”×§×¨×™×˜×™ ×©×—×™×™×‘ ×œ×”×•×¤×™×¢ ×‘×ª×©×•×‘×”.
3. ×”×ª×ž×§×“ ×‘×”× ×—×™×•×ª ×‘×¨×•×¨×•×ª ×•×ž×¢×©×™×•×ª ×œ×©×•××œ.

ðŸ”¹ ×›×ª×•×‘ ×‘×¢×‘×¨×™×ª ×ª×§× ×™×ª, ×¨×”×•×˜×” ×•×¨×©×ž×™×ª.
ðŸ”¹ ×¢× ×” ××š ×•×¨×§ ×‘×”×ª×‘×¡×¡ ×¢×œ ×”×ž×™×“×¢ ×”×‘×.

ðŸ“„ ×ž×™×“×¢ ×¨×œ×•×•× ×˜×™:
{context}

â“ ×©××œ×”:
{question}

ðŸ“ ×ª×©×•×‘×”:
`

const prompt = new PromptTemplate({
  template: PROMPT_TEMPLATE,
  inputVariables: ['context', 'question']
})

const stepbackPrompt = new PromptTemplate({
  template: STEPBACK_PROMPT_TEMPLATE,
  inputVariables: ['context', 'question']
})

async function searchSimilarDocuments(question: string, matchThreshold = 0.75, matchCount = 5) {
  const embedding = await embeddings.embedQuery(question)
  
  const { data: documents, error } = await supabase.rpc('match_documents', {
    query_embedding: embedding,
    match_threshold: matchThreshold,
    match_count: matchCount
  })

  if (error) throw error
  return documents
}

function buildContextFromResults(results) {
  if (!results || results.length === 0) return '';

  // ×§×— ×¢×“ 5 ×ª×•×¦××•×ª
  const limitedResults = results.slice(0, 5);

  // ×§×— ×ž×›×œ ×ª×•×¦××” ×¢×“ 500 ×ª×•×•×™×
  const limitedTexts = limitedResults.map(doc => {
    const title = doc.title ? `Title: ${doc.title}\n` : '';
    const text = doc.plain_text || '';
    const limitedText = text.length > 500 ? text.slice(0, 500) : text;
    return `${title}${limitedText}`;
  });

export async function POST(req: Request) {
  try {
    const { message } = await req.json()
    
    // Search for relevant documents
    const results = await searchSimilarDocuments(message)
    
    if (!results || results.length === 0) {
      // Fallback to general knowledge if no relevant documents found
      const fallbackResponse = await fallbackLLM.call(
        `Answer this question using general knowledge only:\n\n${message}\n\nNote: Add a disclaimer that this is based on general knowledge and not official documents.`
      )
      return NextResponse.json({ 
        answer: fallbackResponse + '\n\n(×”×ª×©×•×‘×” ×ž×‘×•×¡×¡×ª ×¢×œ ×™×“×¢ ×›×œ×œ×™ ×•××™× ×” × ×ª×ž×›×ª ×‘×ž×¡×ž×›×™× ×¨×©×ž×™×™×)',
        sources: [],
        source_type: 'fallback'
      })
    }

    // Build context from results
    const context = buildContextFromResults(results)
    
    // Generate response using stepback prompt
    const stepbackPromptValue = await stepbackPrompt.format({
      context,
      question: message
    })
    
    const response = await llm.call(stepbackPromptValue)
    
    // Return response with sources
    return NextResponse.json({
      answer: response,
      sources: results.map(r => r.title),
      source_type: 'stepback'
    })

  } catch (error) {
    console.error('Error in chat endpoint:', error)
    return NextResponse.json(
      { error: 'Failed to process your request' },
      { status: 500 }
    )
  }
} 